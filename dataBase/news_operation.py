import hashlib
import time
from datetime import datetime
from sentence_transformers import SentenceTransformer
from dataBase.chromaDB import chroma_db
from dataBase.postgreSQL import db

# åˆå§‹åŒ– SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

def is_title_exists(title):
    """æª¢æŸ¥æ–°èæ¨™é¡Œæ˜¯å¦å·²å­˜åœ¨æ–¼è³‡æ–™åº«"""
    conn = chroma_db.get_connection()
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM news WHERE title = %s;", (title,))
    count = cur.fetchone()[0]
    cur.close()
    conn.close()
    return count > 0


# ç”¢ç”Ÿæ–‡æœ¬çš„å‘é‡åµŒå…¥
def create_embeddings(texts):
    return model.encode(texts).tolist()

# å‰µå»ºï¼ˆCreateï¼‰æ–°è
def create_news(title, body, published_time):
    doc_id = hashlib.md5((title + body).encode()).hexdigest()  # ç”¢ç”Ÿå”¯ä¸€ ID
    content = f"{title}\n{body}"
    embedding = create_embeddings([content])[0]  # è½‰æ›ç‚ºå‘é‡

    # è½‰æ›æˆæ¨™æº–æ ¼å¼
    if isinstance(published_time, time.struct_time):
        published_time_str = time.strftime("%Y-%m-%d %H:%M:%S", published_time)
        timestamp = time.mktime(published_time)
    elif isinstance(published_time, datetime):
        published_time_str = published_time.strftime("%Y-%m-%d %H:%M:%S")
        timestamp = published_time.timestamp()
    else:
        raise ValueError("âŒ Unsupported time format")

    # æ–°å¢åˆ°å‘é‡è³‡æ–™åº«
    chroma_db.add_document(
        doc_id,
        content,
        embedding,
        {
            "title": title,
            "published_time": published_time_str,
            "timestamp": timestamp
        }
    )
    print(f"âœ… æ–°èå·²å„²å­˜: {title} - {published_time_str}")

# è®€å–ï¼ˆReadï¼‰æ–°è
def read_news(query_text=None, news_id=None, top_k=5):
    if news_id:  # é€é ID æŸ¥æ‰¾
        result = chroma_db.get_document_by_id(news_id)  # æŸ¥æ‰¾æŒ‡å®š ID çš„æ–°è
        if not result:
            return "âŒ æ‰¾ä¸åˆ°æ­¤æ–°è"
        
        # å¦‚æœæ‰¾åˆ°æ–°èï¼Œè¿”å› IDã€æ¨™é¡Œã€å…§å®¹ç­‰ä¿¡æ¯
        return [{
            "id": news_id,
            "title": result[0].get("title", "ç„¡æ¨™é¡Œ"),
            "content": result[0].get("content", "ç„¡å…§å®¹"),
            "published_time": result[0].get("published_time", "æœªçŸ¥æ™‚é–“")
        }]
    
    if query_text:  # é€éèªæ„æœå°‹
        print(query_text + " searching...")
        embedding = create_embeddings([query_text])[0]  # å‰µå»ºæŸ¥è©¢çš„ embedding
        results = chroma_db.query_documents(query_embedding=[embedding], top_k=top_k)  # æŸ¥è©¢ç›¸é—œçš„æ–°è
        
        if not results["documents"]:
            return "âš ï¸ æ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–°è"
        
        # æ ¹æ“šæä¾›çš„è³‡æ–™çµæ§‹ï¼Œè™•ç†æ¯ç¯‡æ–°è
        news_with_ids = []
        for doc, metadata, score, doc_id in zip(results["documents"][0], results["metadatas"][0], results["distances"][0], results["ids"][0]):
            news_with_ids.append({
                "id": doc_id,  # ä½¿ç”¨æŸ¥è©¢è¿”å›çš„ ID
                "title": metadata.get("title", "ç„¡æ¨™é¡Œ"),
                "content": doc,  # å…§å®¹ç‚ºæŸ¥è©¢è¿”å›çš„æ–‡æª”å…§å®¹
                "published_time": metadata.get("published_time", "æœªçŸ¥æ™‚é–“"),
                "score": score  # è¿”å›ç›¸ä¼¼åº¦åˆ†æ•¸
            })
        
        return news_with_ids
    
    return "âš ï¸ è«‹æä¾›æŸ¥è©¢æ¢ä»¶ï¼ˆæ–°è ID æˆ– æœå°‹é—œéµå­—ï¼‰"

# é€éä½¿ç”¨è€…è¼¸å…¥é€²è¡Œèªæ„æœå°‹
def search_by_user_input():
    while True:
        user_input = input("\nğŸ” è¼¸å…¥æ–°èé—œéµå­—ï¼ˆè¼¸å…¥ 'exit' é€€å‡ºï¼‰ï¼š")
        if user_input.lower() == "exit":
            break
        results = read_news(query_text=user_input, top_k=5)
        
        # ç¢ºèªçµæœæ˜¯åˆ—è¡¨é¡å‹
        if isinstance(results, list):
            print("\nğŸ“Œ ç›¸é—œæ–°èï¼š")
            for idx, doc in enumerate(results, 1):
                # åªé¡¯ç¤º 'title' å’Œ 'id'
                print(f"{idx}. ID: {doc['id']}, Title: {doc['title']}")
        else:
            print(results)  # é¡¯ç¤ºéŒ¯èª¤æˆ–æé†’è¨Šæ¯

def clear_chroma_db():
    all_docs = chroma_db.collection.get(include=["metadatas"])
    for doc_id in all_docs["ids"]:
        chroma_db.delete_news(doc_id)
    print(f"ğŸ§¹ å·²æ¸…ç©ºå‘é‡è³‡æ–™åº«ï¼Œå…± {len(all_docs['ids'])} ç­†")

def rebuild_chroma_from_postgres():
    conn = db.get_connection()
    cur = conn.cursor()
    cur.execute("SELECT title, body, published_at FROM news;")  # ä¸å†ç”¨ idï¼Œè®“ create_news è‡ªå‹•ç”¢ç”Ÿ
    rows = cur.fetchall()

    for title, body, published_at in rows:
        create_news(title, body, published_at)  # ç”± create_news è™•ç†å‘é‡ã€doc_idã€metadata å»ºç«‹

    cur.close()
    db.release_connection(conn)
    print(f"âœ… å·²å°‡ {len(rows)} ç­†è³‡æ–™é‡æ–°å»ºç«‹åˆ°å‘é‡è³‡æ–™åº«")

# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    # create_news("Bitcoin Price Surge", "Bitcoin price has increased by 5% today.", time.gmtime(1709400000))
    # search_by_user_input()
    clear_chroma_db()
    rebuild_chroma_from_postgres()    